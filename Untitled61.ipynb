{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a9f06-0062-4e5e-9b2a-7cf0afe9fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of an event based on new evidence or information. It provides a way to calculate the conditional probability of an event A given that event B has occurred, or vice versa. Bayes' theorem is named after the 18th-century statistician and philosopher Thomas Bayes and is a key tool in Bayesian statistics.\n",
    "\n",
    "Q2. What is the formula for Bayes' theorem?\n",
    "The formula for Bayes' theorem is as follows:\n",
    "\n",
    "\\[P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\\]\n",
    "\n",
    "Where:\n",
    "- \\(P(A|B)\\) is the conditional probability of event A occurring given that event B has occurred.\n",
    "- \\(P(B|A)\\) is the conditional probability of event B occurring given that event A has occurred.\n",
    "- \\(P(A)\\) is the prior probability of event A (the probability of A occurring before considering B).\n",
    "- \\(P(B)\\) is the prior probability of event B (the probability of B occurring before considering A).\n",
    "\n",
    "Q3. How is Bayes' theorem used in practice?\n",
    "Bayes' theorem is used in various fields, including statistics, machine learning, and artificial intelligence, for tasks such as classification, prediction, and inference. Some common applications include spam email filtering, medical diagnosis, document classification, and natural language processing.\n",
    "\n",
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "Bayes' theorem provides a formal way to calculate conditional probabilities. It relates the conditional probability of event A given event B (\\(P(A|B)\\)) to the conditional probability of event B given event A (\\(P(B|A)\\)) and the prior probabilities of A and B (\\(P(A)\\) and \\(P(B)\\)). In essence, it allows us to update our beliefs about the probability of an event based on new evidence or information.\n",
    "\n",
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "The choice of which type of Naive Bayes classifier to use depends on the nature of the problem and the data available. There are three common types of Naive Bayes classifiers:\n",
    "\n",
    "a. Gaussian Naive Bayes: This classifier is suitable for continuous numerical data that follows a Gaussian (normal) distribution. It assumes that the features are normally distributed within each class.\n",
    "\n",
    "b. Multinomial Naive Bayes: This classifier is typically used for discrete data, such as text data, where each feature represents the frequency or occurrence of a specific term. It's well-suited for text classification tasks.\n",
    "\n",
    "c. Bernoulli Naive Bayes: This classifier is used when the features are binary or boolean (e.g., presence or absence of a feature). It's commonly used for document classification or binary decision problems.\n",
    "\n",
    "To choose the appropriate Naive Bayes classifier, you should consider the data type and distribution of your features. Gaussian Naive Bayes is suitable for continuous data, Multinomial Naive Bayes for discrete data, and Bernoulli Naive Bayes for binary data. You should also evaluate the performance of each classifier using techniques like cross-validation to determine which one works best for your specific problem.\n",
    "\n",
    "Q6. Assignment: Which class would Naive Bayes predict the new instance to belong to?\n",
    "To predict the class of a new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we'll calculate the posterior probabilities for both classes (A and B) and choose the class with the higher probability. Since you mentioned equal prior probabilities for each class, we only need to calculate the likelihoods.\n",
    "\n",
    "Let's calculate the likelihoods for both classes:\n",
    "\n",
    "For Class A:\n",
    "- \\(P(X1 = 3 | A) = 4/10\\)\n",
    "- \\(P(X2 = 4 | A) = 3/10\\)\n",
    "\n",
    "For Class B:\n",
    "- \\(P(X1 = 3 | B) = 1/7\\)\n",
    "- \\(P(X2 = 4 | B) = 3/7\\)\n",
    "\n",
    "Now, calculate the posterior probabilities using the Naive Bayes formula:\n",
    "\n",
    "For Class A:\n",
    "\\[P(A | X1 = 3, X2 = 4) = \\frac{P(X1 = 3 | A) \\cdot P(X2 = 4 | A)}{P(X1 = 3) \\cdot P(X2 = 4)}\\]\n",
    "\n",
    "For Class B:\n",
    "\\[P(B | X1 = 3, X2 = 4) = \\frac{P(X1 = 3 | B) \\cdot P(X2 = 4 | B)}{P(X1 = 3) \\cdot P(X2 = 4)}\\]\n",
    "\n",
    "Since the prior probabilities are equal, you can compare \\(P(A | X1 = 3, X2 = 4)\\) and \\(P(B | X1 = 3, X2 = 4)\\) directly to see which class has a higher posterior probability. The class with the higher probability is the predicted class.\n",
    "\n",
    "After performing the calculations, you'll find that \\(P(A | X1 = 3, X2 = 4) > P(B | X1 = 3, X2 = 4)\\). Therefore, Naive Bayes would predict that the new instance belongs to Class A."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
